---
title: "Time series analysis for COVID19 Cases Trends by Country"
author: Andres Hernandez
date: "04/02/2020"
output:
  html_document: default    
  word_document: default
  pdf_document: default 
---

```{r setup, include=FALSE}
library(rjson)
library(CausalImpact)
library(TTR)
library(imputeTS)
library(rlist)
setwd("~/Documents/Projects/Coronavirus/GITCOVID19/COVID19")
graphics.off()
```

## Data Sources
Data for COVID19 updated until April 6th, 2020 comes from [COVID19-TIMESERIES](https://pomber.github.io/covid19/timeseries.json).

Data for Daily testing from [COVID19-TESTING](https://ourworldindata.org/covid-testing)
[COVID19-TESTING-Sources](https://ourworldindata.org/covid-testing#source-information-country-by-country)

Data for european measures can be found in [Report COVID19 Europe](https://www.imperial.ac.uk/media/imperial-college/medicine/mrc-gida/2020-03-30-COVID19-Report-13.pdf)
 
US Data for COVID19 and Testing can be found in the covid tracking project [US COVID19](https://covidtracking.com/data/us-daily)

```{r load, include=FALSE}
result <- fromJSON(file = "timeseries5.json") # data from the COVID19
testing <- read.csv("covid19test4.csv", header = TRUE)
testing_permillion <- read.csv("covid19test_permillion4.csv", header = TRUE)
US_Dataset_State <- fromJSON(file = "timeseriesus1.json")
```

## Processing the data

Data is read by country, change the country for the country of your interest. Then n and interval parameters are used for aggregating data and set the interval of analysis for the time trend. 

n is the aggregation parameter in days, if we set n to 7 we sample cases each week. 

interval parametes choose the number of time periods to take into account for the trending change analysis. (If we select n = 5, interval = 2, it means that the trending change will take into account 10 days before and after to analyze if there was a change in the trending).

Analysis in trending changes is conducted using the causal analysis library. More information about this library refer to the link below. 
[Causal Impact](https://research.google/pubs/pub41854/)
[Paper](https://projecteuclid.org/download/pdfview_1/euclid.aoas/1430226092)

Analysis is conducted over the discrete derivative of the logarithmic of the ratio between the cumulative confirmed cases vs. the total testing, as cases are exponentially distributed the log will result in the linear trend and the derivative will show the pendent. The time series will analyze increasing or decreasing trends on the pendent of the exponential growth rate.

```{r countries, include=FALSE, echo=FALSE}
countries_list <- c(
"Austria",
"Belgium",
"Estonia",
"Iceland",
"Finland",
"France",
"Italy",
"Japan",
"Malaysia",
"South Africa",
"South Korea",
"United Kingdom"
)
```

```{r processing, include=TRUE, warning=FALSE}
#### US Dataset ####
OHList <- list.filter(US_Dataset_State, state == "OH")
US_date <- c()
US_cases <- c()
US_test <- c()

for (element in OHList){
  dateustem <- as.character(element$date) 
  year <- substr(dateustem, 1, 4)
  month <- substr(dateustem, 5, 6)
  day <- substr(dateustem, 7, 8)
  US_date <- c(US_date, paste(year,month,day, sep = "-"))
  US_cases <- c(US_cases, element$positive)
  US_test <- c(US_test, element$positive+element$negative)
} 

US_date <- rev(US_date)
US_cases <- rev(US_cases)
US_test <- rev(US_test)

####

Country <- "Korea, South" # Select the country
Country2 <- "South Korea"
############### CHANGE THE INPUT OF ANALYSIS ############
# "cumulated"
# "tests_int"
# "confirmed"
name_analysis <- "confirmed"

###############################


ResultsByCountry <- result[[Country]] 
CountryNamesList <- strsplit(as.character(testing$Entity), " - ")
CountryName <- c()
for (element in CountryNamesList){
  CountryName <- c(CountryName, element[1])
}
testing$Country <- CountryName

# clipr::write_clip(rownames(as.matrix(table(testing$Country))))
# clipr::write_clip(as.matrix(table(testing$Country)))

TestByCountry <- testing[testing$Country == Country2,] # select country (pendent for creating a 
TestByCountry$TestDate <- as.Date(TestByCountry$Date,format='%B %d, %Y')
TestByCountry$DailyTest <- c(TestByCountry$Cumulative.total.tests[1],diff(TestByCountry$Cumulative.total.tests))

TestByCountry_pm <- testing_permillion[testing$Country == Country2,] # select country (pendent for creating a
TestByCountry_pm$TestDate <- as.Date(TestByCountry$Date,format='%B %d, %Y')

dates <- c()
deaths <- c()
recovered <- c()
confirmed <- c()
tests <- c()
tests_pm <- c()

for(element in ResultsByCountry){
  currentDate <- as.Date(element$date)
  dates <- c(dates, as.character(currentDate))
  deaths <- c(deaths, element$deaths)
  recovered <- c(recovered, element$recovered)
  confirmed <- c(confirmed, element$confirmed)

  if(currentDate %in% TestByCountry$TestDate){
    tests <- c(tests, TestByCountry[TestByCountry$TestDate==currentDate,]$Cumulative.total.tests)
    tests_pm <- c(tests_pm, TestByCountry_pm[TestByCountry_pm$TestDate==currentDate,]$Cumulative.total.tests)
  } else {
    tests <- c(tests, NA)
    tests_pm <- c(tests_pm, NA)
  }
}

data_frame_analysis <- data.frame(dates = as.Date(dates), deaths = deaths, recovered = recovered, confirmed = confirmed, tests = tests, test_pm = tests_pm)

counter <- 0
temp <- rep(TRUE, length(data_frame_analysis$tests))
for (element in data_frame_analysis$tests){
  counter <- counter + 1
  if(is.na(element)){
    temp[counter] <- FALSE
  } else {
    break
  }
}
counter <- length(data_frame_analysis$tests)
for (element in rev(data_frame_analysis$tests)){
  if(is.na(element)){
    temp[counter] <- FALSE
  } else {
    break
  }
  counter <- counter - 1
}

data_frame_analysis_temp <- data_frame_analysis[temp,]
data_frame_analysis_temp$time <- 1:length(data_frame_analysis_temp$tests)
data_frame_analysis_temp$tests_int <- na.kalman(data_frame_analysis_temp$tests)
data_frame_analysis_temp$tests_pm_int <- na.kalman(data_frame_analysis_temp$test_pm)
data_frame_analysis_complete <- data_frame_analysis_temp
dates <- data_frame_analysis_complete$dates

data_frame_analysis_complete$cumulated <- data_frame_analysis_complete$confirmed/data_frame_analysis_complete$tests_int
testing_analysis <- data_frame_analysis_complete$tests_int

#############

analysis <- data_frame_analysis_complete[[name_analysis]]

#####################################

#####
# US ANALYSIS
# analysis <- US_cases
# dates <- US_date
###

CasesAdjusted <- analysis
timeseries_Real_T <- ts(CasesAdjusted, start = 1, end = length(CasesAdjusted))
n <- 2
interval <- 3

dates_resample <- dates[seq(1, length(dates)-n, n)]
timeseries_resample <- timeseries_Real_T[seq(1,length(timeseries_Real_T)-n, n)]
testtsint_resample <- data_frame_analysis_complete$tests_int[seq(1,length(data_frame_analysis_complete$tests_int)-n, n)]

testtsint_resample_pm <- data_frame_analysis_complete$tests_pm_int[seq(1,length(data_frame_analysis_complete$tests_pm_int)-n, n)]

#####
# US_Sample
# testtsint_resample_pm <- US_test
####

dataSMA <- timeseries_resample
pre_data <- dataSMA
pre_data[pre_data==0] <- 0.01 
log_dataSMA <- log(pre_data) # log
first_dev_log_dataSMA <-c(0, diff(log_dataSMA)) # first dev log
first_dev_dataSMA <- c(0,diff(dataSMA)) # Speed
second_dev_dataSMA <- c(0,diff(first_dev_dataSMA)) # Accel
data <- first_dev_log_dataSMA

datatestingSMA <- testtsint_resample
log_datatestingSMA <- log(datatestingSMA+0.001) # log
first_dev_log_datatestingSMA <-c(0, diff(log_datatestingSMA)) # first dev log
first_dev_datatestingSMA <- c(0,diff(datatestingSMA)) # Speed
second_dev_datatestingSMA <- c(0,diff(first_dev_datatestingSMA)) # Accel
datatesting <- first_dev_log_datatestingSMA

data_scaled <- data

startint <- 1
endint <- length(data_scaled)

pvaluesig_ind <- c()
pvaluesig2_ind <- c()
modelbest_ind <- vector(mode="list")
modelbest_ind_report <- c()
pvaluesig_date <- c()

for (element in seq(startint, endint - 2 * interval, 1)){
  testperiod <- element + interval
  pre.period <- c(testperiod-interval, testperiod)
  post.period <- c(testperiod+1, testperiod+1+interval)
  t_name <- paste("mod",as.character(element))
  impact <- CausalImpact(data_scaled, pre.period, post.period, model.args = list(niter = 5000, prior.level.sd = 0.4))
  pvalue <- impact$summary$p[1]
  if(is.null(pvalue)){
    pvaluesig2_ind <- c(pvaluesig2_ind, 1)
    modelbest_ind_report[length(modelbest_ind_report)+1] <- NA
    modelbest_ind[[t_name]] <- NA
  } else {
    pvaluesig2_ind <- c(pvaluesig2_ind, pvalue)
    modelbest_ind_report[length(modelbest_ind_report)+1] <- impact$report
    modelbest_ind[[t_name]] <- impact
  }
  pvaluesig_ind <- c(pvaluesig_ind, testperiod)
  pvaluesig_date <- c(pvaluesig_date, as.character(dates_resample[testperiod]))
}

p_value_area <- c()
for (element in pvaluesig2_ind){
  if(element < 0.05){
    p_value_area <- c(p_value_area, 1)
  } else {
    p_value_area <- c(p_value_area, 0)
  }
}
```
  
## Plotting results

```{r plot, include=TRUE}
red <- 9
blue <- 8
yellow <- 6

# topval <- max(timeseries_resample)
topval <- 0.5
scale <- 0.05
# par(mfrow=c(3,1))
plot(
  1:length(timeseries_resample), 
  timeseries_resample, 
  type = "o",
  col="black",
  pch=18,
  lwd=2,
  lty=1,
  cex=1,
  xaxt="n",
  xlab="",
  ylab = "confirmed/testing (cumulated)",
  ylim = c(0, max(max(timeseries_resample),topval+scale)),
  main = paste(Country, "confirmed vs. testing", sep = " "),
  bty="n"
)
scaled_area <- 100
pvaluesig_ind.2 <- seq(pvaluesig_ind[1], pvaluesig_ind[length(pvaluesig_ind)] + 1 - (1/scaled_area), (1/scaled_area))
p_value_area.2 <- c()
for (element in p_value_area){
  p_value_area.2 <- c(p_value_area.2, rep(element, scaled_area))
}
x.poly <- c(pvaluesig_ind.2, pvaluesig_ind.2[length(pvaluesig_ind.2)], pvaluesig_ind.2[1])
y.poly <- c(p_value_area.2, 0, 0)
polygon(x.poly, y.poly*5000, col=c("#0C92C255"), border=1)
points(
  1:length(testtsint_resample_pm),
  testtsint_resample_pm*(topval/max(testtsint_resample_pm)),
  type = "o",
  col="red",
  pch=18,
  lwd=2,
  lty=1,
  cex=1,
)
#yellow - schools closure
points(
yellow,
0,
cex = 1,
pch=21,  
col = "black",
bg="yellow",
lwd=2,
lty=1,
)
#blue - public events # 10=14-03-2020
points(
blue,
0,
cex = 1,
pch=21,  
col = "black",
bg="blue",
lwd=2,
lty=1,
)
#red - lockdown
points(
red,
0,
cex = 1,
pch=21,  
col = "black",
bg="red",
lwd=2,
lty=1,
)
axis(
  1, 
  at = 1:length(dates_resample), 
  labels = dates_resample, 
  las=2,
  cex.axis=0.7
  )

axis(
  4,
  at = seq(0,topval, scale),
  labels = round(seq(0,max(as.numeric(testtsint_resample_pm)), max(testtsint_resample_pm)/(length(seq(0,topval, scale))-1)), 2),
  las=1,
  cex.axis=0.5,
  pos = length(dates_resample) + 0.5
  )
legend(
  "topleft", 
       legend=c("cases/testing",
                "Testing per thousands (right axis)",
                "School closure",
                "Public events banned",
                "lockdown"
                ),
       col=c("black", "red", "black", "black", "black"), 
       pt.bg=c(NA,NA,"yellow", "blue", "red"),
       lty=c(1, 1, NA, NA, NA),
       lwd=c(2, 2, 2, 2, 2),
       cex=0.6,
       pch=c(18, 18, 21, 21, 21),
       # bty = "n",
       pt.cex = 1
)
plot(
  1:length(data_scaled), 
  data_scaled,
  type = "o",
  col="black",
  pch=18,
  lwd=2,
  lty=1,
  cex=1,
  xaxt="n",
  xlab="",
  ylab = "trending growth rate", #  d2(log(cases))/dt2
  # ylim = c(min(data_scaled[!is.na(data_scaled)]),max(max(data_scaled[!is.na(data_scaled)]),max(datatesting[!is.na(datatesting)]*0.001)))
)
#yellow - schools closure
points(
yellow,
0,
cex = 1,
pch=21,  
col = "black",
bg="yellow",
lwd=2,
lty=1,
)
#blue - public events # 10=14-03-2020
points(
blue,
0,
cex = 1,
pch=21,  
col = "black",
bg="blue",
lwd=2,
lty=1,
)
#red - lockdown
points(
red,
0,
cex = 1,
pch=21,  
col = "black",
bg="red",
lwd=2,
lty=1,
)
polygon(x.poly, y.poly, col=c("#0C92C255"), border=1)
axis(1, at = 1:length(dates_resample), labels =dates_resample, las=2, cex.axis=0.7)
legend(
  "topleft", 
       legend=c("Growth rate d2(Cases/testing)/dt2",
                "School closure",
                "Public events banned",
                "lockdown"
                ),
       col=c("black", "black", "black", "black"), 
       pt.bg=c(NA,"yellow", "blue", "red"),
       lty=c(1, NA, NA, NA),
       lwd=c(2, 2, 2, 2),
       cex=0.6,
       pch=c(18, 21, 21, 21),
       # bty = "n",
       pt.cex = 1
)

```

Blue areas are time periods where the p-value of the trending change resulted in significant results. We usually accept as significant p-value < 0.005.

## Writing the results

```{r summary}
date_analysis <- 18
date_plot <- date_analysis
Country
# summary(modelbest_ind[[paste("mod", date_plot)]])
modelbest_ind_report[date_analysis]
pvaluesig_date[date_analysis]
csresults <- as.data.frame(cbind(as.character(pvaluesig_date), as.numeric(pvaluesig_ind), as.numeric(pvaluesig2_ind)))
names(csresults) <- c("dates", "index", "p-values")
csresults$dates <- as.Date(csresults$dates)
fileout <- merge(data_frame_analysis_complete, csresults, by = "dates", all = TRUE)
filename <- paste("./results/",Country, "_results.csv", sep = "")
if (name_analysis == "cumulated"){
# write.csv(fileout, file=filename, row.names = FALSE)  
}
# plot(modelbest_ind[[paste("mod", date_plot)]])
```

```{r writeeffects}
filename <- paste("_",pvaluesig_date[date_analysis], "_", Country, "_results", sep = "")
filename_impact <- paste("./results/", name_analysis, filename, sep = "")
model_selected <- modelbest_ind[[paste("mod", date_plot)]]
datesnames <- as.character(dates_resample)
test <- model_selected$summary
test2 <- cbind(datesnames, model_selected$series)
filename2 <- paste(filename_impact,"_eff.csv", sep = "")
write.csv(test, file=filename2)
filename3 <- paste(filename_impact, "_series.csv", sep = "")
write.csv(test2, file=filename3)
plot(model_selected)

```

``` {r readresults, include=TRUE}
date <- "2020-03-29"
country <- "United Kingdom"
# type <- "cumulated"
type <- "confirmed"

filename <- paste(country,"_results.csv", sep = "")
folder <- "./Summary/"
folder2 <- paste("./",type,"_cases/",sep="")
filename2 <- paste(type,"_", date, "_", country, "_results_series.csv", sep="")

DataAnalysis <- read.csv(paste(folder,filename,sep = ""))
# max(DataAnalysis$cumulated)
dateeffect <- which(DataAnalysis$dates == date)
startpre <- dateeffect - 6
endpre <- dateeffect - 1
startpos1 <- dateeffect
endpos1 <- dateeffect + 6
startpos6 <- dateeffect + 7
endpos6 <- dateeffect + 12
startpos12 <- dateeffect + 13

avgpre <- mean(DataAnalysis[startpre:endpre,]$cumulated)
avgpos1 <- mean(DataAnalysis[startpos1:endpos1,]$cumulated)
avgpos6 <- mean(na.omit(DataAnalysis[startpos6:endpos6,]$cumulated))
avgpos12 <- mean(na.omit(DataAnalysis[startpos12:length(DataAnalysis$dates),]$cumulated))

DataAnalysis[startpre:endpre,]$dates
DataAnalysis[startpos1:endpos1,]$dates
DataAnalysis[startpos6:endpos6,]$dates
# DataAnalysis[length(DataAnalysis$cumulated),]$dates

mean(na.omit(DataAnalysis[startpos12:length(DataAnalysis$dates),]$cumulated))

result <- cbind(max(DataAnalysis$cumulated), avgpre, avgpos1, avgpos6, avgpos12)
clipboard <- function(x, sep="\t", row.names=FALSE, col.names=FALSE){
  con <- pipe("xclip -selection clipboard -i", open="w")
  write.table(x, con, sep=sep, row.names=row.names, col.names=col.names)
  close(con)
}
result
clipboard(result)

ProjectionAnalysis <- read.csv(paste(folder2,filename2,sep = ""))
firstdate <- ProjectionAnalysis[complete.cases(ProjectionAnalysis),]$datesnames
date_compare <- firstdate[1]
dateeffect <- which(as.character(DataAnalysis$dates) == as.character(date_compare))
e0 <- DataAnalysis[dateeffect-2,]$cumulated

ProjectionAnalysis$proj.response <- e0*exp(ProjectionAnalysis$cum.response)
ProjectionAnalysis$proj.conterfactual <- e0*exp(ProjectionAnalysis$cum.pred)
ProjectionAnalysis$proj.conterfactual.lower <- e0*exp(ProjectionAnalysis$cum.pred.lower)
ProjectionAnalysis$proj.conterfactual.upper <- e0*exp(ProjectionAnalysis$cum.pred.upper)

folder3 <- paste("./projected_",type,"/",sep="")
filename3 <- paste(country, "_", date ,"_",type,"_proj.csv", sep = "")
write.csv(ProjectionAnalysis, file=paste(folder3, filename3, sep=""))
```